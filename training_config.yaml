model:
  checkpoint: "Davlan/xlm-roberta-base-ner-hrl"
  num_labels: 17
  label_list:
    - "O"
    - "B-Name"
    - "I-Name"
    - "B-Position"
    - "I-Position"
    - "B-Company"
    - "I-Company"
    - "B-Address"
    - "I-Address"
    - "B-Phone"
    - "I-Phone"
    - "B-Email"
    - "I-Email"
    - "B-Department"
    - "I-Department"
    - "B-Website"
    - "I-Website"

dataset:
  train_data_path: "/data/clean_ner_data.json"
  val_data_path: "/pytess_ner_data.json"
  max_length: 128
  augmentation:
    prob_space: 0.8
    prob_newline: 0.5
    max_spaces: 10
    replace_prob: 0.3
    remove_diacretic_prob: 0.6

training:
  output_dir: "./output"
  logging_dir: "./output/log"
  metrics_log_path: "./output/metrics.csv"
  learning_rate: 2e-5
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  num_train_epochs: 10
  weight_decay: 0.01
  logging_steps: 10
  logging_strategy: "steps"
  report_to: "none"
  fp16: true
  optim: "paged_adamw_8bit"
  load_best_model_at_end: true
  metric_for_best_model: "f1"
  greater_is_better: true
  save_total_limit: 1
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  lr_scheduler_type: "linear"
  warmup_ratio: 0.1
  save_strategy: "steps"
  save_steps: 100       # Add this line
  eval_strategy: "steps"
  eval_steps: 100
  

inference:
  run_inference: true
  output_path: "./output/inference_results.json"
  inference_data_path: "/pytess_ner_data.json"  # Defaults to val_data_path if not specified